{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter import Api\n",
    "ConsumerSecretApiSecret = 'my-key'\n",
    "ConsumerKeyApiKey = 'my-key'\n",
    "AccessTokenSecret = 'my-key'\n",
    "AccessToken = 'my-key'\n",
    "\n",
    "api = Api(ConsumerKeyApiKey,ConsumerSecretApiSecret,AccessToken,AccessTokenSecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "tags = ['Christmas']\n",
    "tweets_max = 10\n",
    "count=0\n",
    "\n",
    "# Getting tweets related to Christmas\n",
    "for line in api.GetSearch(term = tags, count = tweets_max):\n",
    "    line = json.loads(str(line))\n",
    "    count+=1\n",
    "    #print('******COUNT******',count)\n",
    "    #print(line)\n",
    "    if 'text' in line:\n",
    "        print(\"Text: \", line['text'])\n",
    "        if 'coordinates' in line and line['coordinates'] != None:\n",
    "            print(\"Coordinates: \",line['coordinates'])\n",
    "        try:\n",
    "            if line['retweet_count'] > 0:\n",
    "                print(\"Retweet count: %d\"%line['retweet_count'])\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        print(\"_________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter, re, json\n",
    "\n",
    "# Initializing Twitter object\n",
    "t = twitter.Api(access_token_key=AccessToken, access_token_secret=AccessTokenSecret, consumer_key=ConsumerKeyApiKey, consumer_secret=ConsumerSecretApiSecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** 100 tweets captured ********\n",
      "******** 200 tweets captured ********\n",
      "******** 300 tweets captured ********\n",
      "******** 400 tweets captured ********\n",
      "******** 500 tweets captured ********\n",
      "******** 600 tweets captured ********\n",
      "******** 700 tweets captured ********\n",
      "******** 800 tweets captured ********\n",
      "******** 900 tweets captured ********\n",
      "******** 1000 tweets captured ********\n",
      "******** 1100 tweets captured ********\n",
      "******** 1200 tweets captured ********\n",
      "******** 1300 tweets captured ********\n",
      "******** 1400 tweets captured ********\n",
      "******** 1500 tweets captured ********\n",
      "******** 1600 tweets captured ********\n",
      "******** 1700 tweets captured ********\n",
      "******** 1800 tweets captured ********\n",
      "******** 1900 tweets captured ********\n",
      "******** 2000 tweets captured ********\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "# Max tweets can be anything, time for tweet retrieval increases as the number gets higher\n",
    "max_tweets=2000\n",
    "text=[]\n",
    "\n",
    "# Finding tweets with the most common English words for quantity purposes\n",
    "for line in t.GetStreamFilter(track=['a','the','with','you','when','of','from','this','and','to']):\n",
    "    #print(line)\n",
    "    text.append(line)\n",
    "    if c > max_tweets:\n",
    "        break\n",
    "    c+=1\n",
    "    if c%(max_tweets*.05)==0:\n",
    "        print('********',c,'tweets captured ********')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('1125tweets.csv','w')\n",
    "\n",
    "# Writing each tweet to a file in the format: username,tweet\n",
    "for this in text:\n",
    "    try:\n",
    "        append=''\n",
    "        # Removing all new line characters for file storage purposes\n",
    "        for char in this['text']:\n",
    "            if char !='\\n':\n",
    "                append+=char\n",
    "        f.write(this['user']['name'].rstrip()+','+append+'\\n')\n",
    "        #print(this['text'])\n",
    "        #print(this['user']['name'])\n",
    "        #print(re.findall('\\w+',this['text']))\n",
    "        #print(re.findall('@\\w+',this['text']))\n",
    "        #print('-------------------------------')\n",
    "    except:\n",
    "        pass\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing tweets from file\n",
    "with open('1125tweets.csv','r') as f:\n",
    "    for line in f:\n",
    "        if len(line.split(',')) == 2:\n",
    "            print(line.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark-ing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ùåRick R.‚ùå‚≠ê‚≠ê‚≠ê,RT @grizzlemeister: How cute! This double dose of dipüí©will be known as the Ding Dong Dynamic Duo as the junior idiot elect Ocasio-Cortez ba‚Ä¶',\n",
       " 'Agostinaa,La desperte a candela y se re amotino jajajajjajajjaja que pendejita',\n",
       " 'rissaüåª,Anybody that knows me know how much i love Lion King and how excited i am for this movie üò≠üò©',\n",
       " 'A N N‚ú®,\"Thank you for coming into my life\"\"Thank you for everything\"\"I\\'m so thankful kasi dumating ka sa buhay ko\"\"I lo‚Ä¶ https://t.co/jqFsvJecIS',\n",
       " 'Joe,RT @charlesmurray: What a great set of graphs. https://t.co/ynbv4o2Ewe',\n",
       " 'Excelsior! Chairman Mardikins,RT @ReaperSteven: @BarumDean @KimSJ @DeeJayEsse @Christydyer @LowTaxChloe @bbcpress @bbclaurak @bbcquestiontime @BBCPolitics https://t.co/v‚Ä¶',\n",
       " 'Ny,RT @SoLyrical: I‚Äôm DEAD @ North having a tantrum because Kim won‚Äôt let her write ‚ÄúKKK‚Äù across her face  https://t.co/TM70eAoice',\n",
       " 'Ken George,Next-gen incentive..',\n",
       " 'RT/FV NO FIXADO PFV,RT @plonpy: ‚ò° Gente eu quero achar um guri que eu conheci no inf. 4 no NDC a gente tinha uma amiga chamada Maria Eduarda, o nome dele √© Art‚Ä¶',\n",
       " 'ryou,RT @KinkySexyDana: My bedroom looks good in this one üòâ #pvc #pvcleggings #shinyleggings #latexleggings #latex  #redheels #sexyblonde üíã #RT‚Ä¶']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading tweets with sc object\n",
    "twm = sc.textFile('20ktweets.csv')  # File with ~20,000 tweets\n",
    "twm.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count:\n",
      "\t rt \t 11672\n",
      "\t t \t 9461\n",
      "\t a \t 7802\n",
      "\t https \t 7597\n",
      "\t co \t 7517\n",
      "\t the \t 7270\n",
      "\t to \t 5294\n",
      "\t i \t 4741\n",
      "\t you \t 4091\n",
      "\t and \t 3454\n",
      "\t of \t 3051\n",
      "\t in \t 2726\n",
      "\t is \t 2672\n",
      "\t s \t 2540\n",
      "\t for \t 2456\n",
      "\t de \t 2336\n",
      "\t this \t 2205\n",
      "\t it \t 1975\n",
      "\t me \t 1802\n",
      "\t that \t 1697\n",
      "\n",
      "Positive count:\n",
      "\t like \t 828\n",
      "\t love \t 586\n",
      "\t good \t 407\n",
      "\t thank \t 278\n",
      "\t best \t 220\n",
      "\t happy \t 214\n",
      "\t trump \t 210\n",
      "\t right \t 185\n",
      "\t great \t 167\n",
      "\t win \t 163\n",
      "\t work \t 147\n",
      "\t better \t 141\n",
      "\t enough \t 139\n",
      "\t well \t 134\n",
      "\t won \t 112\n",
      "\t fans \t 101\n",
      "\t pretty \t 95\n",
      "\t liked \t 92\n",
      "\t support \t 91\n",
      "\t top \t 91\n",
      "\n",
      "Negative count:\n",
      "\t shit \t 219\n",
      "\t bad \t 150\n",
      "\t fucking \t 132\n",
      "\t fuck \t 131\n",
      "\t hard \t 111\n",
      "\t bitch \t 96\n",
      "\t wrong \t 90\n",
      "\t hell \t 89\n",
      "\t damn \t 82\n",
      "\t hate \t 81\n",
      "\t miss \t 75\n",
      "\t sad \t 74\n",
      "\t cry \t 69\n",
      "\t sorry \t 63\n",
      "\t lost \t 62\n",
      "\t fake \t 59\n",
      "\t hurt \t 59\n",
      "\t sin \t 58\n",
      "\t die \t 57\n",
      "\t problem \t 54\n",
      "\n",
      "Character count:\n",
      "\t , \t 17816\n",
      "\t  @ \t 15635\n",
      "\t . \t 14994\n",
      "\t : \t 11516\n",
      "\t / \t 7843\n",
      "\t :// \t 7556\n",
      "\t ‚Ä¶ \t 7098\n",
      "\t ‚Äô \t 3858\n",
      "\t ' \t 3027\n",
      "\t  # \t 2645\n",
      "\t ,@ \t 1810\n",
      "\t - \t 1467\n",
      "\t ! \t 1198\n",
      "\t ? \t 1010\n",
      "\t ... \t 785\n",
      "\t ; \t 740\n",
      "\t  - \t 640\n",
      "\t  & \t 597\n",
      "\t  ( \t 524\n",
      "\t : @ \t 461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing .py files\n",
    "import wc,ps,cc,ns\n",
    "\n",
    "# Word count on all tweets\n",
    "it = wc.word_count(twm)\n",
    "print(\"Word count:\")\n",
    "for each in it.take(20):\n",
    "    print('\\t',each[0],'\\t',each[1])\n",
    "print()\n",
    "\n",
    "# Positive word search on tweets\n",
    "ti = ps.positive_count(twm)\n",
    "print(\"Positive count:\")\n",
    "for each in ti.take(20):\n",
    "    print('\\t',each[0],'\\t',each[1])\n",
    "print()\n",
    "\n",
    "# Negative word search on tweets\n",
    "# !!! This contains many curse words !!!\n",
    "ii = ns.negative_count(twm)\n",
    "print(\"Negative count:\")\n",
    "for each in ii.take(20):\n",
    "    print('\\t',each[0],'\\t',each[1])\n",
    "print()\n",
    "\n",
    "# Character count on all tweets\n",
    "tt = cc.char_count(twm)\n",
    "print(\"Character count:\")\n",
    "for each in tt.take(20):\n",
    "    print('\\t',each[0],'\\t',each[1])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
