{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%A Abdou, I.E.',\n",
       " '%A Wong, K.Y.',\n",
       " '%D 1982',\n",
       " '%T Analysis of linear interpolation schemes for bi-level image applications',\n",
       " '%J IBM J Research and Development']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sc.textFile('All.txt',4)  # Text file with ~400k lines of text\n",
    "text.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 192153),\n",
       " ('and', 130177),\n",
       " ('of', 107542),\n",
       " ('to', 70870),\n",
       " ('a', 54480),\n",
       " ('in', 53619),\n",
       " ('i', 42233),\n",
       " ('that', 39658),\n",
       " ('is', 31691),\n",
       " ('he', 30562),\n",
       " ('for', 28383),\n",
       " ('it', 27587),\n",
       " ('with', 27279),\n",
       " ('his', 26246),\n",
       " ('you', 23833),\n",
       " ('not', 23567),\n",
       " ('be', 22997),\n",
       " ('was', 20423),\n",
       " ('as', 20126),\n",
       " ('my', 19492)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile wc.py\n",
    "import re\n",
    "\n",
    "def word_split(row):\n",
    "    words = re.split(\"\\W+\",row)\n",
    "    words = [w.strip().lower() for w in words if w!=\"\"]\n",
    "    return words\n",
    "\n",
    "#text.map(word_split).take(2)\n",
    "\n",
    "# Using Spark to count the word frequencies in the file\n",
    "def word_count(thetext):\n",
    "    return thetext.flatMap(word_split).map(lambda x: (x,1)).reduceByKey(lambda x,y: (x+y)).sortBy(lambda x:-x[1])\n",
    "\n",
    "it = word_count(text)\n",
    "it.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character \":;'/.,<>?)(* count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 281996),\n",
       " ('.', 171010),\n",
       " (\"'\", 41520),\n",
       " (';', 40720),\n",
       " (':', 37684),\n",
       " ('-', 22948),\n",
       " ('?', 15276),\n",
       " (' (', 14632),\n",
       " ('\"', 10710),\n",
       " ('!', 10699),\n",
       " (')', 9697),\n",
       " ('%', 8090),\n",
       " (' -', 3679),\n",
       " ('--', 3612),\n",
       " ('),', 3541),\n",
       " ('.\"', 3541),\n",
       " (',\"', 3446),\n",
       " ('%,', 3173),\n",
       " ('. \"', 2555),\n",
       " (' \"', 2295)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile cc.py\n",
    "import re\n",
    "def char_split(row):\n",
    "    chars = re.split(\"\\w+\",row)\n",
    "    chars = [w.rstrip() for w in chars if w.rstrip()!=\"\"]\n",
    "    return chars\n",
    "\n",
    "#text.map(char_split).take(5)\n",
    "\n",
    "# Using Spark to count the character frequencies in the file\n",
    "def char_count(thetext):\n",
    "    return thetext.flatMap(char_split).map(lambda x: (x,1)).reduceByKey(lambda x,y: (x+y)).sortBy(lambda x:-x[1])\n",
    "\n",
    "a = char_count(text)\n",
    "a.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive word search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 4559),\n",
       " ('well', 4137),\n",
       " ('like', 3991),\n",
       " ('love', 3117),\n",
       " ('great', 2843),\n",
       " ('right', 1588),\n",
       " ('heaven', 1322),\n",
       " ('peace', 1218),\n",
       " ('master', 1167),\n",
       " ('work', 1151),\n",
       " ('better', 1094),\n",
       " ('sweet', 981),\n",
       " ('fair', 948),\n",
       " ('holy', 874),\n",
       " ('gold', 866),\n",
       " ('best', 826),\n",
       " ('grace', 794),\n",
       " ('faith', 735),\n",
       " ('strong', 683),\n",
       " ('noble', 674)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile ps.py\n",
    "\n",
    "import re\n",
    "\n",
    "# List of positive English words\n",
    "positive_words = []\n",
    "with open('positive-words.txt','r') as f:\n",
    "    for line in f:\n",
    "        positive_words.append(line.rstrip())\n",
    "\n",
    "# List of a selection of the top 50 most common English words\n",
    "english_common = []\n",
    "with open('50-english.txt','r') as f:\n",
    "    for line in f:\n",
    "        english_common.append(line.rstrip())\n",
    "\n",
    "def positive_split(row):\n",
    "    words = re.split(\"\\W+\",row)\n",
    "    words = [w.strip().lower() for w in words if w.strip().lower() in positive_words \\\n",
    "             and w.strip().lower() not in english_common and w.strip().lower() != \"\"]\n",
    "    return words\n",
    "\n",
    "#text.map(positive_split).take(2)\n",
    "\n",
    "# Using Spark to count all the positive words in the file\n",
    "def positive_count(thetext):\n",
    "    return thetext.flatMap(positive_split).map(lambda x: (x,1)).reduceByKey(lambda x,y: (x+y)).sortBy(lambda x:-x[1])\n",
    "\n",
    "it = positive_count(text)\n",
    "it.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative word search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('death', 1872),\n",
       " ('fear', 1249),\n",
       " ('poor', 1115),\n",
       " ('dead', 1114),\n",
       " ('die', 888),\n",
       " ('fall', 773),\n",
       " ('evil', 715),\n",
       " ('sin', 632),\n",
       " ('fool', 623),\n",
       " ('lie', 593),\n",
       " ('fell', 592),\n",
       " ('strange', 591),\n",
       " ('lost', 571),\n",
       " ('enemy', 571),\n",
       " ('mistress', 556),\n",
       " ('cry', 554),\n",
       " ('wilt', 547),\n",
       " ('cold', 528),\n",
       " ('break', 518),\n",
       " ('hard', 511)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile ns.py\n",
    "import re\n",
    "\n",
    "# List of negative English words\n",
    "negative_words = []\n",
    "with open('negative-words.txt','r') as f:\n",
    "    for line in f:\n",
    "        negative_words.append(line.rstrip())\n",
    "        \n",
    "# List of a selection of the top 50 most common English words\n",
    "english_common = []\n",
    "with open('50-english.txt','r') as f:\n",
    "    for line in f:\n",
    "        english_common.append(line.rstrip())\n",
    "\n",
    "def negative_split(row):\n",
    "    words = re.split(\"\\W+\",row)\n",
    "    words = [w.strip().lower() for w in words if w.strip().lower() in negative_words \\\n",
    "             and w.strip().lower() not in english_common and w.strip().lower() != \"\"]\n",
    "    return words\n",
    "\n",
    "#text.map(negative_split).take(2)\n",
    "\n",
    "# Using Spark to count all negative words in the file\n",
    "def negative_count(thetext):\n",
    "    return thetext.flatMap(negative_split).map(lambda x: (x,1)).reduceByKey(lambda x,y: (x+y)).sortBy(lambda x:-x[1])\n",
    "\n",
    "it = negative_count(text)\n",
    "it.take(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
